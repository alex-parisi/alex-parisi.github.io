<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Alex Parisi - Style Transfer Web App</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
                  <strong>atparisi.com</strong>
									<!--<a href="index.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a>-->
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/alextparisi/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://github.com/alex-parisi" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
									</ul>
								</header>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Style Transfer</h2>
									</header>
                  <h3>Summary</h3>
                  <p>
                    <img class="image left" src="images/styletransfer.jpg" alt="" />
                    Pictured to the left is the result of applying the style of an abstract painting to a picture of a cute dog.<br><br>
                    I have written a Python package you can install with pip that encapsulates the model and associated evaluation functions into a simple wrapper. You can view the Github and PyPI project pages with the links below, as well as view the original neural network model on Tensorflow Hub.<br>
                    <ul class="actions">
                      <li><a href="https://github.com/alex-parisi/tfhub-styletransfer-wrapper" class="button icon brands fa-github">Github</a></li>
                      <li><a href="https://pypi.org/project/tfhub-styletransfer-wrapper/" class="button">PyPI</a></li>
                      <li><a href="https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2" class="button">TF Hub</a></li>
                    </ul>
                    There is also an accompanying web application I wrote using Flask and deployed on the Google Cloud Application Engine. You can play with it here:<br><br>
                    <ul class="actions">
                      <li><a href="styletransfer.html" class="button">Web App</a></li>
                    </ul>
                  </p>
                </section>
                
                <section>
                  
                  <div class="posts">
                    <article style="width:calc(50% - 6em)">
                      <h3>Usage</h3>
                      First, install the package with pip:
                      <pre>
                        <code>pip install tfhub-styletransfer-wrapper</code>
                      </pre>
                      Then, import the package in Python:
                      <pre>
                        <code>from tfhub_styletransfer_wrapper import StyleHub</code>
                      </pre>
                      Initiate the StyleHub module, and load the content and style images:
                      <pre>
                        <code>stylehub = StyleHub()
stylehub.load_content(content_filename, 512)
stylehub.load_style(style_filename, 256)</code>
                      </pre>
                      Finally, evaluate the model:
                      <pre>
                        <code>stylized_image = stylehub.evaluate()</code>
                      </pre>
                      And save the stylized image:
                      <pre>
                        <code>from tfhub_styletransfer_wrapper import save_image
save_image(stylized_image, output_filename)</code>
                      </pre>
                    </article>
                    
                    
                    <article style="width:calc(50% - 6em)">
                      <h3>Examples</h3>
                      <img class="image fit" src="images/styletransfer-example1.jpg" alt=""/>
                      <img class="image fit" src="images/styletransfer-example2.jpg" alt=""/>
                      <img class="image fit" src="images/styletransfer-example3.jpg" alt=""/>
                      <img class="image fit" src="images/styletransfer-example4.jpg" alt=""/>
                    </article>
                    
                  </div>
                </section>
                
                <section>
                  <h3>How It Works</h3>
                  <p>
                    <a href="https://arxiv.org/pdf/1610.07629.pdf"><img class="image left" src="images/fast_style_transfer_arch-3.jpg" alt="" style="width:100%"></a>
                    The image to the left shows the structure for the arbitrary style transfer model. The style prediction network P predicts an embedding vector S from an input style image, which supplies a set of normalization constants for the style transfer network. <a href="https://arxiv.org/abs/1705.06830">[1]</a><br><br>
                    The style prediction network P is based on the Inception-v3 architecture outlined in <a href="https://arxiv.org/abs/1512.00567">[2]</a> and was developed as a way to scale up network architectures and avoid some of the increase in computational complexity that arises. Developed as an alternative to VGGNet, the Inception architecture offers improvements by avoiding representational bottlenecks, processing higher dimensional representations locally within a network (increasing the activations per tile), and factorizing large convolution filters into smaller ones.
                  </p>
                  <p>
                    <a href="https://cloud.google.com/tpu/docs/inception-v3-advanced"><img class="image right" src="images/inceptionv3.png" alt="" style="max-width:60%"></a>
                    The Inception-v3 model is made up of both symmetric and asymmetric blocks like convolutions, average pooling, max pooling, concatinations, dropouts, and fully connected layers. Typically, each layer implements batch normalization, and the loss is computed using Softmax. The image on the right details the model architecture for Inception-v3.<br><br>
                    The style transfer network T is a convolutional neural network formulated in the structure of an image encoder/decoder. The mean is computed across each channel of the Inception-v3 output S, which is then connected to two fully connected networks to predict the final embeddings. The overall effect of the style transfer network is that it will shift the mean and variance of the content image in an attempt to match the mean and variance of the style image's features.
                  </p>
                </section>
                
                <section>
                  <h3>References</h3>
                  <p>[1] Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens. <a href="https://arxiv.org/abs/1705.06830">Exploring the structure of a real-time, arbitrary neural artistic stylization network</a>. Proceedings of the British Machine Vision Conference (BMVC), 2017.</p>
                  <p>[2] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna. <a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a>. In IEEE Computer Vision and Pattern Recognition (CVPR), 2015.</p>
                  <p>[3] Xun Huang, Serge Belongie. <a href="https://arxiv.org/abs/1703.06868">Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</a>. In ICCV, 2017</p>
                  
                  
                </section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
                    <li><span class="opener active" style="color:#f56a6a">Style Transfer</span>
                      <ul>
                        <li><a href="styletransfer.html">Web App</a></li>
                        <li><a href="styletransfer-info.html" style="color:#f56a6a">Project Info</a></li>
                      </ul>
                    </li>
                    <li><a href="dcgan-info.html">DCGAN<a></li>
									</ul>
								</nav>

							<!-- Footer -->
								<footer id="footer">
									<p>Last Updated: 02/01/2022</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
